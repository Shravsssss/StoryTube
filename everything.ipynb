{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coref resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ujwal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clsuters:-\n",
      "[[3, 4], [6, 6], [18, 18], [26, 26], [47, 48], [67, 67], [89, 89], [101, 101], [103, 103], [110, 110], [114, 114]]\n",
      "[[22, 23], [31, 31]]\n",
      "[[34, 34], [42, 42], [51, 52], [55, 55], [57, 57], [62, 63]]\n",
      "[[80, 80], [83, 83]]\n",
      "\n",
      "\n",
      "\n",
      "Coref resolved:  Once there lived a crow. a crow wished to be colorful and beautiful like other birds. \n",
      "a crow then went to the parrot and shared a crow's thoughts. \n",
      "But the parrot said \"Peacock is most beautiful bird so talk to Peacock\". \n",
      "Then a crow went to Peacock and told Peacock about Peacock's looks. \n",
      "Then Peacock replied, \"a crow are the luckiest bird that has been never caged in life and we because of we's beauty stay caged, and a crow are always free.\"\n",
      "After listening to this, a crow realized a crow's mistake and thanked God for making a crow like this and a crow flew away happily.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load saved model\n",
    "with open('allen_coref' , 'rb') as f:\n",
    "    predictor = pickle.load(f)\n",
    "\n",
    "#text = \"\"\"A cat is walking on a sunny day. It jumped over a stone. It died. Dog is walking in the opposite direction. It ran. The dog said \"Hello world\".\"\"\"\n",
    "text = \"\"\"Once there lived a crow. He wished to be colorful and beautiful like other birds. \n",
    "He then went to the parrot and shared his thoughts. \n",
    "But parrot said \"Peacock is most beautiful bird so talk to him\". \n",
    "Then the crow went to the peacock and told him about his looks. \n",
    "Then the peacock replied, \"You are the luckiest bird that has been never caged in life and we because of our beauty stay caged, and you are always free.\"\n",
    "After listening to this, crow realized his mistake and thanked God for making him like this and he flew away happily.\"\"\"\n",
    "prediction = predictor.predict(document=text)  # get prediction\n",
    "print(\"Clsuters:-\")\n",
    "for cluster in prediction['clusters']:\n",
    "    print(cluster)  # list of clusters (the indices of spaCy tokens)\n",
    "# Result: [[[0, 3], [26, 26]], [[34, 34], [50, 50]]]\n",
    "print('\\n\\n') #Newline\n",
    "\n",
    "coref_text = predictor.coref_resolved(text)\n",
    "\n",
    "print('Coref resolved: ', coref_text)  # resolved text\n",
    "# Result: Joseph Robinette Biden Jr. is an American politician who is the 46th and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAO parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat walks rapidly on a sunny day\n",
      "[<SV, A cat, walks, None, None, None, [rapidly, on a sunny day]>]\n",
      " A cat fell over a stone\n",
      "[<SVA,  A cat, fell, None, None, None, [over a stone]>]\n",
      " A cat died\n",
      "[<SV,  A cat, died, None, None, None, []>]\n",
      " Dog said \"Hello World\"\n",
      "[(' Dog', 'said', 'Hello World')]\n",
      "\n",
      "[]\n",
      "[<SV, A cat, walks, None, None, None, [rapidly, on a sunny day]>, <SVA,  A cat, fell, None, None, None, [over a stone]>, <SV,  A cat, died, None, None, None, []>, (' Dog', 'said', 'Hello World')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from clausIE import svo\n",
    "\n",
    "coref_text = \"\"\"A cat walks rapidly on a sunny day. A cat fell over a stone. A cat died. Dog said \"Hello World\".\"\"\"\n",
    "SVOs = []\n",
    "for line in coref_text.split('.'):\n",
    "    SVO = svo.get_svos(line)\n",
    "    result = re.search(r\"([\\\"\\'])(?:(?=(\\\\?))\\2.)*?\\1\", line)\n",
    "    if result:\n",
    "        SVO = [(str(SVO[0].subject), str(SVO[0].verb), result.group().strip(\"\\\"\"))]\n",
    "    print(line)\n",
    "    print(SVO)\n",
    "    SVOs += (SVO)\n",
    "\n",
    "print(SVOs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\hddstuds\\capstone\\StoryTube\\everything.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/hddstuds/capstone/StoryTube/everything.ipynb#Y123sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     verb \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/hddstuds/capstone/StoryTube/everything.ipynb#Y123sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     verb\u001b[39m.\u001b[39mappend(svo[\u001b[39m1\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/hddstuds/capstone/StoryTube/everything.ipynb#Y123sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     verb\u001b[39m.\u001b[39mappend(svo[\u001b[39m2\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/hddstuds/capstone/StoryTube/everything.ipynb#Y123sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/hddstuds/capstone/StoryTube/everything.ipynb#Y123sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     verb \u001b[39m=\u001b[39m svo[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "stop_words = set(stopwords.words('english'))\n",
    "svos = defaultdict(list)\n",
    "\n",
    "for svo in SVOs: \n",
    "    subject = svo[0]\n",
    "    word_tokens = word_tokenize(subject)\n",
    "    filtered_sentence = [w.lower() for w in word_tokens if not w.lower() in stop_words]\n",
    "    if svo[1] == \"said\":\n",
    "        verb = []\n",
    "        verb.append(svo[1])\n",
    "        verb.append(svo[2])\n",
    "    else:\n",
    "        verb = svo[1]\n",
    "    svos[\"\".join(filtered_sentence)].append(verb)\n",
    "    \n",
    "svos = dict(svos)\n",
    "print(svos)\n",
    "\n",
    "charcaters = list(i.lower() for i in svos.keys())\n",
    "print(charcaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "actions_movement = {'die' : 0, 'fall' : 0, 'hurt' : 0, 'idle' : 0, 'jump' : 1, 'run' : 1, 'slide' : 1, 'walk' : 1, 'say': 0}\n",
    "#word2vec similarity between the incoming action vs the ones we have in list of actions and then set a threshold and execute the action based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shour\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shour\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"said\",'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walk']\n",
      "['walk', 'jump']\n",
      "['walk', 'jump', 'die']\n",
      "{'walk': [<Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>], 'jump': [<Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>], 'die': [<Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>]}\n",
      "['walk']\n",
      "['walk', 'run']\n",
      "['walk', 'run', 'say']\n",
      "{'walk': [<Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>], 'run': [<Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>, <Surface(200x200x32 SW)>], 'say': [<Surface(200x200x32 SW)>]}\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "walk\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "jump\n",
      "0\n",
      "run\n",
      "0\n",
      "die\n",
      "0\n",
      "say\n",
      "dialogie played\n",
      "1\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "0\n",
      "674\n",
      "True\n",
      "die\n",
      "1\n",
      "674\n",
      "True\n",
      "326\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from numpy import character\n",
    "import pygame\n",
    "import glob\n",
    "from time import sleep\n",
    "\n",
    "from gtts import gTTS\n",
    "\n",
    "\n",
    "\n",
    "language = 'en'\n",
    "\n",
    "SIZE = WIDTH, HEIGHT = 1280, 720 #the width and height of our screen\n",
    "FPS = 7 #Frames per second\n",
    "\n",
    "screen = pygame.display.set_mode(SIZE)\n",
    "bg = pygame.transform.scale(pygame.image.load('pygame\\sunny_day.png') , SIZE)\n",
    "\n",
    "dir_list = {'r' : 200, 'l' : 400} #moving towards which direction\n",
    "\n",
    "dialogues = []\n",
    "dialogue_count = 0\n",
    " \n",
    "class MySprite(pygame.sprite.Sprite):\n",
    "\n",
    "    def __init__(self, char, x, y, dir):\n",
    "        super(MySprite, self).__init__()\n",
    "        \n",
    "        self.images = {}\n",
    "        self.actions = []\n",
    "        # self.images = [pygame.image.load(img) for img in glob.glob(\"pygame\\\\cat\\\\*.png\")]\n",
    "        for action in svos[char]:\n",
    "            if type(action) == list:\n",
    "                dialogues.append(action[1])\n",
    "            action = WordNetLemmatizer().lemmatize(action[0] if type(action) == list else action,'v')   \n",
    "            self.actions.append(action)\n",
    "            print(self.actions)\n",
    "            \n",
    "            if action not in self.images:\n",
    "                self.images[action] = [pygame.transform.scale(pygame.image.load(img) , (200,200)) for img in glob.glob(\"pygame\\\\\" + char + \"\\\\\" + action + \"*.png\")]\n",
    "            \n",
    "        print(self.images)\n",
    "        self.char = char\n",
    "        self.index = 0\n",
    "        self.action_count = 0\n",
    "        self.dir = dir\n",
    "        self.x = x\n",
    "        self.y = y   \n",
    "\n",
    "    def play_dialogue(self, index):\n",
    "        myobj = gTTS(text=dialogues[index], lang=language, slow=False)\n",
    "        myobj.save(\"dialogue.mp3\")\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(\"dialogue.mp3\")\n",
    "        pygame.mixer.music.set_volume(1)\n",
    "        pygame.mixer.music.play()\n",
    "        \n",
    "    def movement_update(self):\n",
    "        # if self.x == 880:\n",
    "        #     self.dir = 'l'\n",
    "        # elif self.x == 0:\n",
    "        #     self.dir = 'r'\n",
    "\n",
    "        if self.dir == 'r':                        \n",
    "            self.x += FPS\n",
    "        else:\n",
    "            self.image = pygame.transform.flip(self.image, True, False)\n",
    "            self.x -= FPS\n",
    "        screen.blit(self.image, (self.x, self.y))\n",
    " \n",
    "    def update(self):\n",
    "        # print(self.index, self.action_count, len(self.actions), len(self.images[self.actions[self.action_count]]))\n",
    "        print(self.actions[self.action_count])\n",
    "        if self.actions[self.action_count] == \"say\":\n",
    "            global dialogue_count\n",
    "            self.play_dialogue(dialogue_count)\n",
    "            dialogue_count += 1\n",
    "            print(\"dialogie played\")\n",
    "        if self.index >= len(self.images[self.actions[self.action_count]]):\n",
    "            if self.action_count >= len(self.actions) - 1:\n",
    "                return 1\n",
    "            self.index = 0\n",
    "            self.action_count += 1\n",
    "        self.image = self.images[self.actions[self.action_count]][self.index]\n",
    "        self.index += 1\n",
    "\n",
    "        if actions_movement[self.actions[self.action_count]]:\n",
    "            self.movement_update()\n",
    "        else:\n",
    "            screen.blit(self.image, (self.x, self.y))\n",
    "        \n",
    "        return 0\n",
    "\n",
    "    def update_idle(self):\n",
    "        self.image = pygame.transform.scale(pygame.image.load(\"pygame\\\\\" + self.char + \"\\\\\" + \"idle1.png\") , (200,200))\n",
    "        flip_var = True if self.dir == \"l\" else False\n",
    "        print(flip_var)\n",
    "        self.image = pygame.transform.flip(self.image, flip_var, False)\n",
    "        screen.blit(self.image, (self.x, self.y))\n",
    "        \n",
    " \n",
    "def main():\n",
    "    pygame.init()\n",
    "    pygame.display.set_caption(\"Trace\")\n",
    "    char_objects = []\n",
    "    for i in range(len(charcaters)):\n",
    "        dir = list(dir_list.keys())[i % 2]\n",
    "        char_objects.append(MySprite(charcaters[i], dir_list[dir] * ((i % 2) + 1), 350, dir))\n",
    "    # my_group = pygame.sprite.Group(my_sprite)\n",
    "    idle_char = []\n",
    "    clock = pygame.time.Clock()\n",
    "    \n",
    "    loop = 1\n",
    "    count = 0 # number of characters whos actions have been completed\n",
    "\n",
    "\n",
    "    return_val = 0\n",
    "    while count < len(charcaters): \n",
    "\n",
    "        pygame.event.get() \n",
    "        \n",
    "        screen.fill((0,0,0))        \n",
    "        screen.blit(bg, (0, 0))\n",
    "\n",
    "        for char in char_objects:\n",
    "            return_val = char.update()   \n",
    "            print(return_val) \n",
    "            if return_val == 1:\n",
    "                char_objects.remove(char)\n",
    "                idle_char.append(char)\n",
    "                count += return_val\n",
    "        \n",
    "        for char in idle_char:\n",
    "            print(char.x)\n",
    "            char.update_idle()\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(FPS)\n",
    "\n",
    "    pygame.quit()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import spacy.cli\n",
    "# Download following once\n",
    "#spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CS', 24, 26, 'ORG'), ('MIT', 48, 51, 'ORG')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Victoria was a major in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Victoria studies at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MIT\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Victoria was a major in CS. Victoria studies at MIT.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)\n",
    "# now we use displaycy function on doc2\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "  \n",
    "# This module is imported so that we can \n",
    "# play the converted audio\n",
    "import os\n",
    "  \n",
    "# The text that you want to convert to audio\n",
    "mytext = 'Welcome to geeksforgeeks!'\n",
    "  \n",
    "# Language in which you want to convert\n",
    "language = 'en'\n",
    "  \n",
    "# Passing the text and language to the engine, \n",
    "# here we have marked slow=False. Which tells \n",
    "# the module that the converted audio should \n",
    "# have a high speed\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "  \n",
    "# Saving the converted audio in a mp3 file named\n",
    "# welcome \n",
    "myobj.save(\"welcome.mp3\")\n",
    "  \n",
    "# Playing the converted file\n",
    "os.system(\"mpg321 welcome.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat is walking on a sunny day. A cat jumped. A cat was talking with a human and died. Dog is walking in the opposite direction. Dog ran.\n",
      "Token A POS: DET, dep: det\n",
      "Token cat POS: NOUN, dep: nsubj\n",
      "Token is POS: AUX, dep: aux\n",
      "Token walking POS: VERB, dep: ROOT\n",
      "Token on POS: ADP, dep: prep\n",
      "Token a POS: DET, dep: det\n",
      "Token sunny POS: ADJ, dep: amod\n",
      "Token day POS: NOUN, dep: pobj\n",
      "Token . POS: PUNCT, dep: punct\n",
      "Token A POS: DET, dep: det\n",
      "Token cat POS: NOUN, dep: nsubj\n",
      "Token jumped POS: VERB, dep: ROOT\n",
      "Token . POS: PUNCT, dep: punct\n",
      "Token A POS: DET, dep: det\n",
      "Token cat POS: NOUN, dep: nsubj\n",
      "Token was POS: AUX, dep: aux\n",
      "Token talking POS: VERB, dep: ROOT\n",
      "Token with POS: ADP, dep: prep\n",
      "Token a POS: DET, dep: det\n",
      "Token human POS: NOUN, dep: pobj\n",
      "Token and POS: CCONJ, dep: cc\n",
      "Token died POS: VERB, dep: conj\n",
      "Token . POS: PUNCT, dep: punct\n",
      "Token Dog POS: PROPN, dep: nsubj\n",
      "Token is POS: AUX, dep: aux\n",
      "Token walking POS: VERB, dep: ROOT\n",
      "Token in POS: ADP, dep: prep\n",
      "Token the POS: DET, dep: det\n",
      "Token opposite POS: ADJ, dep: amod\n",
      "Token direction POS: NOUN, dep: pobj\n",
      "Token . POS: PUNCT, dep: punct\n",
      "Token Dog POS: PROPN, dep: nsubj\n",
      "Token ran POS: VERB, dep: ROOT\n",
      "Token . POS: PUNCT, dep: punct\n",
      "svo:, subject: a cat a cat a cat dog dog, verb: walking jumped talking died walking ran, attribute: , question: False, wh_word: \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# object and subject constants\n",
    "OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
    "# tags that define wether the word is wh-\n",
    "WH_WORDS = {\"WP\", \"WP$\", \"WRB\"}\n",
    "\n",
    "# extract the subject, object and verb from the input\n",
    "def extract_svo(doc):\n",
    "    sub = []\n",
    "    at = []\n",
    "    ve = []\n",
    "    for token in doc:\n",
    "        # is this a verb?\n",
    "        if token.pos_ == \"VERB\":\n",
    "            ve.append(token.text)\n",
    "        # is this the object?\n",
    "        if token.dep_ in OBJECT_DEPS or token.head.dep_ in OBJECT_DEPS:\n",
    "            at.append(token.text)\n",
    "        # is this the subject?\n",
    "        if token.dep_ in SUBJECT_DEPS or token.head.dep_ in SUBJECT_DEPS:\n",
    "            sub.append(token.text)\n",
    "    return \" \".join(sub).strip().lower(), \" \".join(ve).strip().lower(), \" \".join(at).strip().lower()\n",
    "\n",
    "# wether the doc is a question, as well as the wh-word if any\n",
    "def is_question(doc):\n",
    "    # is the first token a verb?\n",
    "    if len(doc) > 0 and doc[0].pos_ == \"VERB\":\n",
    "        return True, \"\"\n",
    "    # go over all words\n",
    "    for token in doc:\n",
    "        # is it a wh- word?\n",
    "        if token.tag_ in WH_WORDS:\n",
    "            return True, token.text.lower()\n",
    "    return False, \"\"\n",
    "\n",
    "# gather the user input and gather the info\n",
    "doc = nlp(\"A cat is walking on a sunny day. A cat jumped. A cat was talking with a human and died. Dog is walking in the opposite direction. Dog ran.\")\n",
    "print(doc)\n",
    "# print out the pos and deps\n",
    "for token in doc:\n",
    "    print(\"Token {} POS: {}, dep: {}\".format(token.text, token.pos_, token.dep_))\n",
    "\n",
    "# get the input information\n",
    "subject, verb, attribute = extract_svo(doc)\n",
    "question, wh_word = is_question(doc)\n",
    "print(\"svo:, subject: {}, verb: {}, attribute: {}, question: {}, wh_word: {}\".format(subject, verb, attribute, question, wh_word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
